### zookeeper

![img](c:/users/administrator/appdata/local/ynote/data/m15135158097@163.com/7cec5787e25d458faece358746b3dc3a/clipboard.png)

**Zookeeper运用场景**

- 数据发布与订阅：

**引子**

云计算越来越流行的今天，单一机器处理能力已经不能满足我们的需求，不得不采用大量的服务集群。服务集群对外提供服务的过程中，有很多的配置需要随时更新，服务间需要协调工作，这些信息如何推送到各个节点？并且保证信息的一致性和可靠性？

众所周知，分布式协调服务很难正确无误的实现，它们很容易在竞争条件和死锁上犯错误。如何在这方面节省力气？Zookeeper是一个不错的选择。 Zookeeper背后的动机就是解除分布式应用在实现协调服务上的痛苦。本文在介绍Zookeeper的基本理论基础上，用Zookeeper实现了一 个配置管理中心，利用Zookeeper将配置信息分发到各个服务节点上，并保证信息的正确性和一致性。

**Zookeeper是什么？**

引用官方的说法：“Zookeeper是一个高性能，分布式的，开源分布式应用协调服务。它提供了简单原始的功能，分布式应用可以基于它实现更高级 的服务，比如同步，配置管理，集群管理，名空间。它被设计为易于编程，使用文件系统目录树作为数据模型。服务端跑在java上，提供java和C的客户端 API”。

**Zookeeper总体结构**

Zookeeper服务自身组成一个集群(2n+1个服务允许n个失效)。Zookeeper服务有两个角色，一个是leader，负责写服务和数据同步，剩下的是follower，提供读服务，leader失效后会在follower中重新选举新的leader。

Zookeeper逻辑图如下，

![img](c:/users/administrator/appdata/local/ynote/data/m15135158097@163.com/6007d6043ede4350953874b8d8bb8ccf/151024_hgtu.jpeg)

1. 客户端可以连接到每个server，每个server的数据完全相同。
2. 每个follower都和leader有连接，接受leader的数据更新操作。
3. Server记录事务日志和快照到持久存储。
4. 大多数server可用，整体服务就可用。

**Zookeeper数据模型**

Zookeeper表现为一个分层的文件系统目录树结构（不同于文件系统的是，节点可以有自己的数据，而文件系统中的目录节点只有子节点）。

数据模型结构图如下，

![img](c:/users/administrator/appdata/local/ynote/data/m15135158097@163.com/6697942ef35949c393c9d64bb0a5e7a9/5151024_qy6o.png)

圆形节点可以含有子节点，多边形节点不能含有子节点。一个节点对应一个应用，节点存储的数据就是应用需要的配置信息。

**Zookeeper 特点**

- 顺序一致性：按照客户端发送请求的顺序更新数据。
- 原子性：更新要么成功，要么失败，不会出现部分更新。
- 单一性 ：无论客户端连接哪个server，都会看到同一个视图。
- 可靠性：一旦数据更新成功，将一直保持，直到新的更新。
- 及时性：客户端会在一个确定的时间内得到最新的数据。

**Zookeeper运用场景**

- 数据发布与订阅 （我的业务用到这个特性，后面会有详细介绍）

应用配置集中到节点上，应用启动时主动获取，并在节点上注册一个watcher，每次配置更新都会通知到应用。

- 名空间服务

分布式命名服务，创建一个节点后，节点的路径就是全局唯一的，可以作为全局名称使用。

- 分布式通知/协调

不同的系统都监听同一个节点，一旦有了更新，另一个系统能够收到通知。

- 分布式锁

Zookeeper能保证数据的强一致性，用户任何时候都可以相信集群中每个节点的数据都是相同的。一个用户创建一个节点作为锁，另一个用户检测该节点，如果存在，代表别的用户已经锁住，如果不存在，则可以创建一个节点，代表拥有一个锁。

- 集群管理

每个加入集群的机器都创建一个节点，写入自己的状态。监控父节点的用户会受到通知，进行相应的处理。离开时删除节点，监控父节点的用户同样会收到通知。（dubbo注册机制）

**Zookeeper工作流程**

![img](c:/users/administrator/appdata/local/ynote/data/m15135158097@163.com/22db2534f1c74e88a5932d2e6754ae06/clipboard.png)



| **零件**   | **描述**                                                     |
| ---------- | ------------------------------------------------------------ |
| Write      | 写过程由领导节点处理。 领导者将写请求转发到所有znode，并等待znode的答案。 如果znode的一半回复，则写入过程完成。 |
| Read       | 读取由特定连接的znode在内部执行，因此不需要与群集交互。      |
| 复制数据库 | 它用于在zookeeper中存储数据。 每个znode都有自己的数据库，每个znode在一致性的帮助下每次都有相同的数据。 |
| Leader     | Leader是负责处理写入请求的Znode。                            |
| Follower   | 关注者从客户端接收写请求并将它们转发到领导znode。            |
| 请求处理器 | 只存在于领导节点。 它管理来自从节点的写请求。                |
| 原子广播   | 负责将从领导节点到从节点的变化广播。                         |

### 搭建zookeeper集群：

（1）搭建三台虚拟机，IP地址如下

192.168.202.128

192.168.202.129

192.168.202.130

（2）每台虚拟机安装zookeeper服务

（3）修改zookeeper配置文件zoo.cfg,在文件的最后追加如下内容：

server.1=192.168.202.128:2888:3888 
server.2=192.168.202.129:2888:3888
server.3=192.168.202.130:2888:3888

2888代表集群机器间心跳检测端口；3888代表选举通讯端口

（3）每个虚拟机的zookeeper安装数据目录添加 myid文件名

192.168.202.128 上的myid内容为1对应server.1

192.168.202.129 上的myid内容为2对应server.2

192.168.202.130 上的myid内容为1对应server.3

### zookeeper选举算法：

zookeeper使用zab协议（paxos协议简化版）：投票选举算法，最终结果选举产生leader和follwer

### zookeeper客户端命令

（1）自带客户端命令：zkCli.sh

（2）查看根目录下的内容：ls /

（3）